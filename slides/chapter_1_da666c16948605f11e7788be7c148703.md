---
title: Insert title here
key: da666c16948605f11e7788be7c148703

---
## Lesson 3.1: Workings and some theory of AR model

```yaml
type: "TitleSlide"
key: "a8666f30be"
```

`@lower_third`

name: Gourav S B
title: Instructor at DataCamp


`@script`
Hi there! Today we will learn about the workings of an Auto-regression model.


---
## Lesson Objectives:

```yaml
type: "FullSlide"
key: "e2e5569f67"
center_content: true
```

`@part1`
1. AR Model and its mathematical form
2. Assumptions behind AR modelling
3. Apply AR model in python


`@script`
After going through this lesson you will be 
1) Able to describe an auto-regression model 
2) Understand the assumptions behind it
3) Learn how to apply the AR model in python


---
## Theory of AR Model

```yaml
type: "FullSlide"
key: "79bc718a82"
center_content: true
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4370/datasets/6ec14fc97a7538d4efb7f5a237df61247994fe13/Screenshot%202019-01-03%20at%2012.43.18%20AM.png) 
NOTE: It is not necessary for the time series to be stationary to apply AR model.


`@script`
Let's begin by understanding the theory of AR model. 

A time series data that has a set of data points that linearly depend upon its past instances can use the Auto-Regression Model to predict the future instances.

Such a process can be written as shown here.

Where **Xt** is the value to be predicted at time "t",
      **Xt-1** is the value at time "t-1" or 1-time lag,
      similarly, **Xt-2*** is the 2-time lag and so on,
      **phis'** are the weights that the model will predict, which are to be multiplied with the corresponding previous time lag values.

Et is the error term or noise at time "t".

So we need to determine how many time lags are to be considered by the model ie denoted by "p" previous time lags.

In short, we have "**a sum of weighted previous time lags**" to forecast the future values. 

Interestingly, the time series do not need to be stationary to apply AR model, so we need not worry about the stationary test learnt earlier in the past lessons.


---
## Calculation of significant lag values "P" in a AR(P) model

```yaml
type: "FullSlide"
key: "f01bab6a05"
```

`@part1`
```python
from statsmodels.tsa.ar_model import AR
from sklearn.metrics import mean_squared_error
df = pd.read_csv("jj.data") # Import the JJ data
X = df.values
nobs = len(X) # Number of observations
train, test = X[1:nobs-8], X[nobs-8:]
model = AR(train) # train an AutoRegression model

default_lag = round(12*(nobs/100.)**(1/4.))

model_fit = model.fit()
print ("Lag in model_fit: %s" % model_fit.k_ar)
model_fit_1 = model.fit(maxlag=8)
print ("Lag in model_fit_1: %s" % model_fit_1.k_ar)
model_fit_2 = model.fit(maxlag=8,ic="aic")
print ("Lag in model_fit_2: %s" % model_fit_2.k_ar)

Lag in model_fit: 11
Lag in model_fit_1: 8
Lag in model_fit_2: 5

https://www.statsmodels.org/dev/generated/statsmodels.tsa.ar_model.AR.fit.html#statsmodels.tsa.ar_model.AR.fit.html
```


`@script`
Let's begin by finding the value of "P-the number of previous time lags" in the AR(P) model using the statsmodel package.

We will be using the same Johnson&Johnson-data seen earlier to understand this concept. 

First, we extract the return values of JJ-data and split it into train and test set. The last 8 quarters will be our test set. 

Next we will train the AR object on the train data using the function AR() imported from the statsmodel.tsa package. 

Next we will learn how to calculate the significant number of time lags, ie which past instances have a significant ripple effect on the future instances. For this, we have two main parameters (maxlag - "maximum lag" and ic - "information criteria") which govern what will be the allowed number of time lags for the model to be built.

We will see three methods to find the value of "p":
1) In case when the 2 parameters are missing, the default value of "p" is calculated as shown here. Interestingly, "p" is directly proportional to the nobs, so more observations means more significant time lags will be added to the model. In our case, 11 is the default value.

2)Next we can also specify the value of "p" using the maxlag parameter as shown here.

3)Finally we can let the model decide the value of "p". As here maxlag value is altered between 1-8, while measuring the error using the Akaike Information Criterion(aic). Here we get 5 as the significant number of time-lags. There are other values of the parameter "ic" which you can explore from here.


---
## Prediction of quarterly returns for last 2 years using AR(11) model

```yaml
type: "FullCodeSlide"
key: "82b866b3e9"
```

`@part1`
```python
predictions = model_fit.predict(start=len(train), end=len(train)+len(test)-1, 
dynamic=False) # make predictions

for i in range(4): # Looking at the first year prediction
    print("predicted=%f, actual=%f" % (predictions[i], test[i]))

print("Test MSE: %.3f" % mean_squared_error(test, predictions))

print("Coefficients: %s" % model_fit.params)

pyplot.plot(test,label="Actual")
pyplot.plot(predictions, color="red",label="Predicted")
pyplot.ylabel("Quarterly Returns($)")
pyplot.xlabel("Quarter")
pyplot.show()
```
```python
Test MSE: 0.600
predicted=14.095006, actual=14.040000
predicted=13.896251, actual=12.960000
predicted=13.574049, actual=14.850000
predicted=10.463847, actual=9.990000
Coefficients: [ 0.05739753  0.13081868  0.22824468  0.11240213  0.87438022 
-0.32461781 0.104462 -0.0935553....]

```


`@script`
Now we will predict the return values of the last 2 years using the AR(11) model with 11 significant previous time lags using the model_fit object we trained earlier.

As these values are sequentially ordered we pass the values to the predict function with the help of this code.

Using the mean_squared_error as the measure we get 0.6, which means our predicted values are very close to the actual ones.

One interesting thing to note here is that all the 11 values of phi estimated, will always be between -1 and 1, which means only a part of the past signal is carried forward.

This block of code gives us the plot for the actual and the predicted values for the last eight quarters.


---
## Plot comparing the actual  and predicted quarterly returns for the year 1979 and 1980

```yaml
type: "FullSlide"
key: "432fa90067"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4370/datasets/8332371ffb092b70b5a14d2c607476f2febebdb2/lesson_3_1.png)


`@script`
The blue line is the actual return and the red line is the predicted return. Evidently, the AR model has done a good job in learning the trend from the past returns.


---
## Let's fit some AR model!

```yaml
type: "FinalSlide"
key: "7d7d9a328f"
assignment: "ACF & AR model and how they can be used together to understand time series data."
```

`@script`
Now let us fit some AR models.

