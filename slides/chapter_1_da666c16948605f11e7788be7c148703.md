---
title: Insert title here
key: da666c16948605f11e7788be7c148703

---
## Lesson 3.1: Workings and some theory of AR model

```yaml
type: "TitleSlide"
key: "a8666f30be"
```

`@lower_third`

name: Gourav S B
title: Instructor at DataCamp


`@script`
Hi there! I am Gourav and today we will learn about the workings and some theory of AR or Auto-regression model.


---
## Lesson Objectives:

```yaml
type: "FullSlide"
key: "e2e5569f67"
center_content: true
```

`@part1`
1. AR Model and its mathematical form
2. Assumptions behind AR modelling
3. Apply AR model in python
4. Use ACF in AR model


`@script`
After this lesson you will be 
1) able to describe an auto-regression model with its mathematical equation,
2) understand the various assumptions required for validating an implementation of AR model on a given time series data,
3) Learn how to apply an AR model in python and 
4) finally use Auto-Correlation function learnt in the previous lesson to help select the time lags for an AR model.


---
## Theory of AR Model

```yaml
type: "FullSlide"
key: "79bc718a82"
center_content: true
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4370/datasets/6ec14fc97a7538d4efb7f5a237df61247994fe13/Screenshot%202019-01-03%20at%2012.43.18%20AM.png) 
NOTE: It is not necessary for the time series to be stationary to apply AR model.


`@script`
Let's begin by understanding the theory of AR model. If we have a time series data which depends linearly on its past instances then we can model such a data using Auto-regression model. Essentially the value of the future instances are governed by past values. 
The mathematical notation of such process can be written as shown here. Where Xt is the value at instance time "t" and phi is the weights that the model predicts to be multiplied with the previous time lags and Et is the error term. Essentially, we have "a sum of weighted previous time lags" to forecast the future values. 
Interestingly, the time series do not need to be stationary to apply AR model so we need not worry about the stationary test learnt earlier in the past lesson.


---
## Using AR model to predict JJ shares quarterly returns

```yaml
type: "FullCodeSlide"
key: "413b57aa92"
```

`@part1`
First, lets view the JJ shares data and print the co-relation for 1 time lag using pandas corr() function
```python
import pandas as pd
# Reading the Johnson-&-Johnson shares quarterly returns data
df = pd.read_csv("jj.data")
df["date"] = pd.to_datetime(df["date"])# Convert date to pandas datetime object
df.set_index("date",inplace=True) # Set index of df as date
print(df.head(4)) # View the structured data of 1960
            return
date             
1960-03-31   0.71
1960-06-30   0.63
1960-09-30   0.85
1960-12-31   0.44
```

```python
shifted_df = pd.concat([df["return"].shift(1), df["return"]], axis=1)
shifted_df.columns = ["return at t-1", "return at t+1"]
print(shifted_df.corr())
              return at t-1  return at t+1
return at t-1      1.000000      0.944936
return at t+1      0.944936      1.000000
```


`@script`
Lets begin by applying the AR model to the JJ data.

First, let's load and view the JJ data in the pandas data frame using this piece of code. The JJ data has two columns; one for the quarter dates for 20 years and second for returns realised in dollars. We load the data using pandas and convert the date column to timeseries object followed by setting it as index. So the head of data looks as shown here.

Now we want to see the correlation in values with one time lag ie. upon shifting the "return" column by one row up what is the correlation between the values at (t-1) and (t+1). We can use the inbuilt function corr() to find the correlation. Surprisingly, it turns out to be 0.94 which means they are highly co-related.


---
## Lag calculation within AR.fit() method of "statsmodels" package

```yaml
type: "FullSlide"
key: "f01bab6a05"
```

`@part1`
```python
from statsmodels.tsa.ar_model import AR
from sklearn.metrics import mean_squared_error

X = df.values
nobs = len(X) # Number of observations
train, test = X[1:nobs-8], X[nobs-8:]
model = AR(train) # train an AutoRegression model

# The internal formula inside the AR.fit() method to
# calculate default lag in case maxlag and ic parameter are missing
default_lag = round(12*(nobs/100.)**(1/4.))
print ("Default lag value %f as obtained from formula" % default_lag)
# Fit the unconditional maximum likelihood of an AR(p) process
model_fit = model.fit()
print ("Lag in model_fit: %s" % model_fit.k_ar)
model_fit_1 = model.fit(maxlag=8)
print ("Lag in model_fit_1: %s" % model_fit_1.k_ar)
model_fit_2 = model.fit(maxlag=8,ic="aic")
print ("Lag in model_fit_2: %s" % model_fit_2.k_ar)

Default lag value 11.0 as obtained from formula
Lag in model_fit: 11
Lag in model_fit_1: 8
Lag in model_fit_2: 5
```


`@script`
Now lets apply AR model available in the stats model package of python. For that we import the required model statsmodel.tsa.ar_model and we will be using the mean_squared_error to measure how well our prediction are.

 We extract the return values of dataframe and split it to train and test set here. The last two years or 8 quarters is our testset. Next we initiate the AR object on the train data. 

In the next block of code we will try to understand how to find the significant time lags to be used for our train set.There are parameters (max lag and ic) which govern what will be the allowed number of time lags for the model.

First, lets look at how the default internal lag value is calculated in the AR in case when the two params are missing. The formula is shown here which depends upon number of observations and the value is 11 in this case. Essentially this is directly proportional to the nobs so more the observations more will the significant time lags be added into the model.

Second we can specify the maxlag parameter directly as in model_fit_1.

Finally we can ask the model to fit the data for all the values between 1 to maxlag=8, and based on error measure such as "Akaike Information Criterion" we get 5 as significant number of time lags.


---
## Predict quarterly returns for last two years using AR(11) model

```yaml
type: "FullCodeSlide"
key: "82b866b3e9"
```

`@part1`
```python
print("Coefficients: %s" % model_fit.params)
predictions = model_fit.predict(start=len(train), end=len(train)+len(test)-1, 
dynamic=False) # make predictions
for i in range(len(predictions)):
    print("predicted=%f, expected=%f" % (predictions[i], test[i]))
error = mean_squared_error(test, predictions)
print("Test MSE: %.3f" % error)
pyplot.plot(test,label="Actual")
pyplot.plot(predictions, color="red",label="Predicted")
pyplot.ylabel("Quarterly Returns($)")
pyplot.xlabel("Quarter")
pyplot.show() # plot the prediction
```

```python
Lag in model_fit: 11
Coefficients: [ 0.05739753  0.13081868  0.22824468  0.11240213  0.87438022 
-0.32461781 0.104462 -0.0935553   0.45528992 -0.05165633 -0.40466646  0.057615]
predicted=14.095006, expected=14.040000
predicted=13.896251, expected=12.960000
predicted=13.574049, expected=14.850000
predicted=10.463847, expected=9.990000
predicted=17.347931, expected=16.200000
predicted=15.504115, expected=14.670000
predicted=15.822432, expected=16.020000
predicted=11.725124, expected=11.610000
Test MSE: 0.600
```


`@script`



---
## Predicted quarterly returns for the year 1979 and 1980

```yaml
type: "FullSlide"
key: "432fa90067"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4370/datasets/8332371ffb092b70b5a14d2c607476f2febebdb2/lesson_3_1.png)


`@script`



---
## How to use ACF to better estimate the significant time lags

```yaml
type: "FullCodeSlide"
key: "2976f30bd6"
```

`@part1`
```python
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.tsa.stattools import acf
plot_acf(df, lags=12)
plot_acf(model_fit.predict(start=12,end=79,dynamic=False), lags=12)
pyplot.show()

ACF_df = pd.DataFrame(columns=["ACF from actual data","ACF from fitted model"])
ACF_df["ACF from actual data"] = acf(df,nlags=12)
ACF_df["ACF from fitted model"] = acf(model_fit.predict(start=12,end=80,
dynamic=False),nlags=12)
print (ACF_df)
    ACF from actual data  ACF from fitted model
0               1.000000               1.000000
1               0.925102               0.894762
2               0.888263               0.817167
3               0.832848               0.808366
4               0.824077               0.788722
5               0.763800               0.698282
6               0.717595               0.634483
7               0.675024               0.620639
8               0.654356               0.596962
9               0.608335               0.515699
10              0.564152               0.472320
11              0.525560               0.463515
12              0.500414               0.438432
```


`@script`



---
## ACF plot for the data and fitted model

```yaml
type: "FullImageSlide"
key: "e2cad4c24c"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4370/datasets/b2523944cd8748a7481a4d18dd72872a61932668/Screenshot%202019-01-03%20at%201.37.58%20AM.png)


`@script`



---
## Let's fit some AR model!

```yaml
type: "FinalSlide"
key: "7d7d9a328f"
assignment: "ACF & AR model and how they can be used together to understand time series data."
```

`@script`
Now let's fit some AR model by doing the following excerises!

